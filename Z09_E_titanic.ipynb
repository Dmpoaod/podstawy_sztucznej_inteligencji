{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "BR-eEKCfGxMX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGazH2opGxMZ"
      },
      "source": [
        "# titanic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9FgEXSTGxMa"
      },
      "source": [
        "Najpierw zaloguj się do https://www.kaggle.com/ i przejdź do wyzwania https://www.kaggle.com/c/titanic, aby pobrać \n",
        " * train.csv i test.csv. \n",
        "\n",
        "Zapisz je w katalogu datasets/titanic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "zA4hoWT5GxMa"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "vNRgI8vhGxMa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
        "#     csv_path = os.path.join(titanic_path, filename)\n",
        "#     return pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qFWjI-ieGxMa"
      },
      "outputs": [],
      "source": [
        "train_data = \"train.csv\"\n",
        "test_data = \"test.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keFfI3pKGxMb"
      },
      "source": [
        "* Dane są już podzielone na zestaw treningowy i zestaw testów. \n",
        "* Jednak dane testowe nie zawierają etykiet: Twoim celem jest wyszkolenie najlepszego modelu, który możesz wykorzystać w danych treningowych, następnie dokonanie swoich przewidywań na danych testowych i przesłanie ich do Kaggle, aby zobaczyć ostateczny wynik.\n",
        "\n",
        "Rzućmy okiem na kilka pierwszych rzędów zestawu treningowego:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xYqh_ZzgGxMb",
        "outputId": "4f21bd3c-a095-4f58-8fdd-02dfd82eeae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c4dda1b59424>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'head'"
          ]
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T11Zytq1GxMb"
      },
      "source": [
        "The attributes have the following meaning:\n",
        "\n",
        "* Survived: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
        "* Pclass: passenger class.\n",
        "* Name, Sex, Age: self-explanatory\n",
        "* SibSp: how many siblings & spouses of the passenger aboard the Titanic.\n",
        "* Parch: how many children & parents of the passenger aboard the Titanic.\n",
        "* Ticket: ticket id\n",
        "* Fare: price paid (in pounds)\n",
        "* Cabin: passenger's cabin number\n",
        "* Embarked: where the passenger embarked the Titanic\n",
        "* Let's get more info to see how much data is missing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Hb5lIMRTGxMc",
        "outputId": "d1b2a02f-d4fe-4a83-8f36-f82d4e5890f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-60f4b0d084c6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'info'"
          ]
        }
      ],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68FHBl_6GxMc"
      },
      "source": [
        "Atrybuty **Age**, **Cabin** oraz **Embarked** są czasami zerowe (mniej niż 891 wartości bez wartości null), szczególnie w przypadku **Cabin** (77% ma wartość zerową). Zignorujemy teraz **Cabin** i skupimy się na reszcie. Atrybut **Age** ma około 19% wartości pustych, więc będziemy musieli zdecydować, co z nimi zrobić. Zastąpienie wartości null medianą wieku wydaje się uzasadnione.\n",
        "\n",
        "Atrybuty **Name** i **Ticket** mogą mieć pewną wartość, ale będą one nieco trudne do przekształcenia w użyteczne liczby. Na razie będziemy je ignorować.\n",
        "\n",
        "Rzućmy okiem na atrybuty liczbowe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MEA_BIH5GxMc",
        "outputId": "52c3e076-cd87-45e4-b928-380a76ee1a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a461722943bc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'describe'"
          ]
        }
      ],
      "source": [
        "train_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeNaS4zEGxMc"
      },
      "source": [
        "* Tylko 38% przeżyło: to wystarczająco blisko do 40%, więc **accuracy** będzie rozsądną miarą do oceny naszego modelu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDXc9igwGxMc"
      },
      "source": [
        "Sprawdźmy, czy etykiety przyjmują wartości 0 lub 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-iuPoRHpGxMd"
      },
      "outputs": [],
      "source": [
        "train_data[\"Survived\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnd9WhRyGxMd"
      },
      "source": [
        "Nie zapomnij o etykietach:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qkq8ap3BGxMd"
      },
      "outputs": [],
      "source": [
        "train_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data.drop(['Survived'], axis=1)\n",
        "y = train_data['Survived'].values\n",
        "np.unique(y)\n",
        "y[ y == ' <=50K'] = 0\n",
        "y[ y == ' >50K'] = 1\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "print(\"X.shape: {} y.shape: {}\".format(X.shape, y.shape))"
      ],
      "metadata": {
        "id": "qSx1KPfMHEC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "L8LCb5rcGxMd"
      },
      "outputs": [],
      "source": [
        "y_train = X.values\n",
        "X_train = X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrnY7GR3GxMd"
      },
      "source": [
        "Teraz rzućmy okiem na wszystkie atrybuty kategoryczne:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ldPSAnebGxMd"
      },
      "outputs": [],
      "source": [
        "train_data[\"Cabin\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "t03HLlW8GxMd"
      },
      "outputs": [],
      "source": [
        "train_data[\"Sex\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4MCWkM4KGxMd"
      },
      "outputs": [],
      "source": [
        "train_data[\"Ticket\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"Embarked\"].value_counts()"
      ],
      "metadata": {
        "id": "JBDG1v5dHLvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixWVeJbEGxMd"
      },
      "source": [
        "Atrybut **Embarked** mówi nam, gdzie pasażer zaokrętował: C = Cherbourg, Q = Queenstown, S = Southampton.\n",
        "\n",
        "Teraz zbudujmy nasze **pipeline** preprocessingu. \n",
        "\n",
        "Wykorzystamy DataframeSelector aby wybrać określone atrybuty z DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C75MRQKDGxMe"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# A class to select numerical or categorical columns \n",
        "# since Scikit-Learn doesn't handle DataFrames yet\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS0rN6MsGxMe"
      },
      "source": [
        "Zbudujmy **pipeline** dla atrybutów numerycznych:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YMIhkrKbGxMe"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        (\"select_numeric\", DataFrameSelector([\"Fare\"])),\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "02K6JIjpGxMe"
      },
      "outputs": [],
      "source": [
        "num_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ye-SenpGxMe"
      },
      "source": [
        "Będziemy także potrzebować imputera do kategorycznych kolumn  napisowych (zwykły Imputer nie działa na tych kolumnach):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-4LiPKLwGxMe"
      },
      "outputs": [],
      "source": [
        "# Inspired from stackoverflow.com/questions/25239958\n",
        "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
        "                                        index=X.columns)\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.fillna(self.most_frequent_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f0aWZy2GxMe"
      },
      "source": [
        "Teraz możemy zbudować **pipeline** dla atrybutów kategorycznych:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tlDsgnrOGxMe"
      },
      "outputs": [],
      "source": [
        "# from future_encoders import OneHotEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "        (\"select_cat\", DataFrameSelector([\"Cabin\", \"Embarked\", \"Ticket\", \"Sex\"])),\n",
        "        (\"imputer\", MostFrequentImputer()),\n",
        "        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore')),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-jLLGqfsGxMe"
      },
      "outputs": [],
      "source": [
        "cat_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xddYbHPbGxMe"
      },
      "source": [
        "Na koniec połączmy powyższe podejścia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "58hbl-2XGxMf"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
        "        (\"num_pipeline\", num_pipeline),\n",
        "        (\"cat_pipeline\", cat_pipeline),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qcpu07WnGxMf"
      },
      "source": [
        "Teraz mamy fajny **pipeline** przetwarzania wstępnego, który pobiera dane wejściowe i zwraca dane wyjściowe złorzone z liczb, które możemy podać do dowolnego modelu uczenia maszynowego."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zngp8VwHGxMf"
      },
      "source": [
        "# Zad\n",
        "\n",
        "Robimy StratifiedKFold i znajdujemy optymalne parametry dla\n",
        "\n",
        "* SVM z jądrem rbf\n",
        "* SVM z jądrem poly\n",
        "* SVM liniowego\n",
        "* Regresji logistycznej"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T6LFrgUfGxMf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "seed=123\n",
        "kfold = StratifiedKFold(n_splits=5)\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "pipe = Pipeline([\n",
        "    ('preprocessing', preprocess_pipeline), \n",
        "    ('classifier', SVC(kernel='linear'))])\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "grid_1 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
        "\n",
        "grid_1.fit(X_train, y_train)\n",
        "grid_1.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe2 = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', SVC(kernel='rbf'))])\n",
        "\n",
        "param_grid2 = {\n",
        "            'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "grid_2 = GridSearchCV(pipe2, param_grid2, cv=kfold, return_train_score=True)\n",
        "\n",
        "grid_2.fit(X_train, y_train)\n",
        "grid_2.best_params_"
      ],
      "metadata": {
        "id": "R6agFGk5H4kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "pipe4 = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', LogisticRegression())])\n",
        "\n",
        "param_grid4 = {\n",
        "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "            'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none']\n",
        "}\n",
        "\n",
        "grid_4 = GridSearchCV(pipe4, param_grid4, cv=kfold, return_train_score=True)\n",
        "\n",
        "grid_4.fit(X_train, y_train)\n",
        "grid_4.best_params_"
      ],
      "metadata": {
        "id": "cDZw6yoGIC08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TkowPGAKGxMf"
      },
      "outputs": [],
      "source": [
        "from sklearn import  metrics\n",
        "\n",
        "\n",
        "models = []\n",
        "models.append(('SVM linear', grid_1.best_estimator_))\n",
        "\n",
        "\n",
        "\n",
        "precision_score = []\n",
        "recall_score = []\n",
        "f1_score = []\n",
        "accuracy_score = []\n",
        "for name, model in models:\n",
        "    print(name)\n",
        "    print(\"precision_score: {}\".format(metrics.precision_score(y_test, model.predict(X_test)) ))\n",
        "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test)) ))\n",
        "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test)) ))\n",
        "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
        "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test)))\n",
        "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test)))\n",
        "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test)))\n",
        "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d4eo6z3LGxMf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "d = {'precision_score': precision_score, \n",
        "     'recall_score': recall_score, \n",
        "     'f1_score': f1_score,\n",
        "     'accuracy_score' : accuracy_score\n",
        "    }\n",
        "df = pd.DataFrame(data=d)\n",
        "df.insert(loc=0, column='Method', value=['SVM linear'])\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}